"""åˆ›å»ºç¤ºä¾‹æ•°æ®æ–‡ä»¶ - æ¼”ç¤ºæ­£ç¡®çš„æ•°æ®æ ¼å¼"""

import numpy as np
import pandas as pd
from pathlib import Path
from PIL import Image
import io


def create_sample_parquet_data(output_dir: str = "data/sample", num_samples: int = 100):
    """
    åˆ›å»ºç¤ºä¾‹parquetæ•°æ®æ–‡ä»¶
    
    Args:
        output_dir: è¾“å‡ºç›®å½•
        num_samples: æ ·æœ¬æ•°é‡
    """
    output_dir = Path(output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)
    
    print(f"ğŸ“ åˆ›å»ºç¤ºä¾‹æ•°æ®åˆ°: {output_dir}")
    
    # å‚æ•°è®¾ç½®
    sequence_length = 16  # æ¯ä¸ªè§†é¢‘åºåˆ—çš„å¸§æ•°
    frame_size = (224, 224)
    
    # 1. åˆ›å»ºvideo_stream_1.parquet
    print("\n1ï¸âƒ£ åˆ›å»º video_stream_1.parquet...")
    video1_data = []
    
    for i in range(num_samples):
        # ä¸ºæ¯ä¸ªæ ·æœ¬åˆ›å»ºä¸€ä¸ªè§†é¢‘åºåˆ—ï¼ˆ16å¸§ï¼‰
        frames = []
        for t in range(sequence_length):
            # åˆ›å»ºä¸€ä¸ªå½©è‰²å›¾åƒï¼ˆè“è‰²æ¸å˜ï¼‰
            img = np.zeros((*frame_size, 3), dtype=np.uint8)
            img[:, :, 2] = int(100 + 100 * (t / sequence_length))  # è“è‰²é€šé“æ¸å˜
            
            # æ·»åŠ ä¸€äº›è¿åŠ¨ï¼ˆç§»åŠ¨çš„åœ†åœˆï¼‰
            center_x = int(frame_size[1] * (0.3 + 0.4 * np.sin(2 * np.pi * t / sequence_length)))
            center_y = int(frame_size[0] * 0.5)
            
            y, x = np.ogrid[:frame_size[0], :frame_size[1]]
            mask = (x - center_x)**2 + (y - center_y)**2 <= 20**2
            img[mask] = [255, 0, 0]  # çº¢è‰²åœ†åœˆ
            
            # å°†å›¾åƒè½¬æ¢ä¸ºbytesï¼ˆå¯é€‰ï¼Œä¹Ÿå¯ä»¥ç›´æ¥å­˜numpyæ•°ç»„ï¼‰
            pil_img = Image.fromarray(img)
            img_bytes = io.BytesIO()
            pil_img.save(img_bytes, format='PNG')
            frames.append(img_bytes.getvalue())
        
        video1_data.append({
            'sample_id': i,
            'frames': frames  # å­˜å‚¨ä¸ºbytesåˆ—è¡¨
        })
    
    df_video1 = pd.DataFrame(video1_data)
    df_video1.to_parquet(output_dir / 'video_stream_1.parquet')
    print(f"âœ“ ä¿å­˜ {len(df_video1)} ä¸ªæ ·æœ¬åˆ° video_stream_1.parquet")
    
    # 2. åˆ›å»ºvideo_stream_2.parquet
    print("\n2ï¸âƒ£ åˆ›å»º video_stream_2.parquet...")
    video2_data = []
    
    for i in range(num_samples):
        frames = []
        for t in range(sequence_length):
            # åˆ›å»ºç»¿è‰²æ¸å˜çš„å›¾åƒ
            img = np.zeros((*frame_size, 3), dtype=np.uint8)
            img[:, :, 1] = int(100 + 100 * (t / sequence_length))  # ç»¿è‰²é€šé“
            
            # æ·»åŠ ä¸åŒçš„è¿åŠ¨æ¨¡å¼
            center_x = int(frame_size[1] * 0.5)
            center_y = int(frame_size[0] * (0.3 + 0.4 * np.cos(2 * np.pi * t / sequence_length)))
            
            y, x = np.ogrid[:frame_size[0], :frame_size[1]]
            mask = (x - center_x)**2 + (y - center_y)**2 <= 15**2
            img[mask] = [0, 255, 255]  # é’è‰²åœ†åœˆ
            
            pil_img = Image.fromarray(img)
            img_bytes = io.BytesIO()
            pil_img.save(img_bytes, format='PNG')
            frames.append(img_bytes.getvalue())
        
        video2_data.append({
            'sample_id': i,
            'frames': frames
        })
    
    df_video2 = pd.DataFrame(video2_data)
    df_video2.to_parquet(output_dir / 'video_stream_2.parquet')
    print(f"âœ“ ä¿å­˜ {len(df_video2)} ä¸ªæ ·æœ¬åˆ° video_stream_2.parquet")
    
    # 3. åˆ›å»ºlabels.parquet
    print("\n3ï¸âƒ£ åˆ›å»º labels.parquet...")
    labels_data = []
    
    for i in range(num_samples):
        # ç”Ÿæˆéšæœºçš„deltaå‘é‡ (dx, dy, dz)
        # èŒƒå›´åœ¨ [-0.1, 0.1] ä¹‹é—´
        delta = np.random.uniform(-0.1, 0.1, size=3).astype(np.float32)
        
        labels_data.append({
            'sample_id': i,
            'delta': delta.tolist()  # è½¬ä¸ºåˆ—è¡¨å­˜å‚¨
        })
    
    df_labels = pd.DataFrame(labels_data)
    df_labels.to_parquet(output_dir / 'labels.parquet')
    print(f"âœ“ ä¿å­˜ {len(df_labels)} ä¸ªæ ‡ç­¾åˆ° labels.parquet")
    
    # 4. æ˜¾ç¤ºæ•°æ®æ ¼å¼
    print("\n" + "="*60)
    print("ğŸ“‹ æ•°æ®æ ¼å¼ç¤ºä¾‹:")
    print("="*60)
    
    print("\nğŸ“ video_stream_1.parquet ç»“æ„:")
    print(df_video1.head(2))
    print(f"   - sample_id: {df_video1['sample_id'].dtype}")
    print(f"   - frames: list of {len(df_video1.iloc[0]['frames'])} images (bytes)")
    
    print("\nğŸ“ video_stream_2.parquet ç»“æ„:")
    print(df_video2.head(2))
    
    print("\nğŸ“ labels.parquet ç»“æ„:")
    print(df_labels.head(5))
    print(f"   - sample_id: {df_labels['sample_id'].dtype}")
    print(f"   - delta: shape {np.array(df_labels.iloc[0]['delta']).shape}, dtype float32")
    
    print("\n" + "="*60)
    print("âœ… ç¤ºä¾‹æ•°æ®åˆ›å»ºå®Œæˆï¼")
    print("="*60)
    print("\nä¸‹ä¸€æ­¥:")
    print(f"  python train_simple.py \\")
    print(f"    --video1 {output_dir}/video_stream_1.parquet \\")
    print(f"    --video2 {output_dir}/video_stream_2.parquet \\")
    print(f"    --labels {output_dir}/labels.parquet \\")
    print(f"    --config configs/default.yaml")


if __name__ == '__main__':
    import argparse
    
    parser = argparse.ArgumentParser(description="åˆ›å»ºç¤ºä¾‹parquetæ•°æ®")
    parser.add_argument('--output-dir', type=str, default='data/sample',
                       help='è¾“å‡ºç›®å½•')
    parser.add_argument('--num-samples', type=int, default=100,
                       help='æ ·æœ¬æ•°é‡')
    args = parser.parse_args()
    
    create_sample_parquet_data(args.output_dir, args.num_samples)